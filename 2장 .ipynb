{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2장  시작하기 전에: 신경망의 수학적 구성 요소.\n",
    "\n",
    "# 2.1 신경망과의 첫 만남.\n",
    "\n",
    "# 머신 러닝에서 분류 문제의 범주를 클래스 라고 합니다.\n",
    "# 데이터 포인트는 샘플이라고 합니다. \n",
    "# 특정 샘플의 클래스는 레이블 이라고 합니다.\n",
    "\n",
    "# 신경망의 핵슴 구성 요소는 일종의 데이터 처리 필터라고 생각할 수 있는 층(layer).\n",
    "# 층은 주어진 문제에 더 의미 있는 표현을 입력된 데이터로부터 추출합니다.\n",
    "\n",
    "# loss function(손실 함수) : 훈련 데이터에서 신경망의 성능을 측정하는 방법 -> 네트워크가 옳은 방향으로 학습되게 도와줌.\n",
    "# optimizer(옵티마이저) : 입력된 데이터와 손실 함수 기반 네트워크를 업데이트\n",
    "# 훈련과 테스트 과정을 모니터링할 지표 : 여기에선 정확도만 고려.\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# 신경망 구조.\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# 컴파일 단계.\n",
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# 이미지 데이터 준비하기.\n",
    "# 이 데이터를 0 과 1 사이의 값을 가지는 float32 타입의 (60000, 28 * 28) 크기의 배열로 바꿉니다. \n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 신경망을 위한 데이터 표현.\n",
    "\n",
    "모든 머신 러닝 시스템은 텐서를 기본 데이터 구조로 사용합니다.\n",
    "\n",
    "스칼라 0D 텐서 - 하나의 숫자만 담고 있는 텐서를 스칼라 라고 부릅니다. \n",
    "\n",
    "벡터 1D 텐서 - 딱 하나의 축을 가집니다. \n",
    "\n",
    "행렬 2D 텐서 - 행렬에는 2 개의 축이 있습니다. \n",
    "\n",
    "3D 텐서와 고차원 텐서 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 타입(넘파이에서 dtype에 저장됩니다.) 텐서에 포함된 데이터의 타입.\n",
    "# float32, uint8, float64 등이 될 수 있음. \n",
    "\n",
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(60000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(train_images.ndim) # train_images 배열의 ndim 속성으로 축의 개수를 확인. \n",
    "print(train_images.shape) # 배열의 크기. \n",
    "print(train_images.dtype) # 데이터 타입.  \n",
    "# 즉 이 배열은 8 bit 정수형 3D 텐서입니다. 좀 더 정확하게는 28 x 28 크기의 저수 행렬 6 만 개가 가지고 있는 배열 입니다. \n",
    "# 각 행렬은 하나의 흑백 이미지이고, 각 원소는 0에서 255 사이의 값을 가집니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 다섯 번쨰 이미지 출력하기.\n",
    "digit = train_images[4] \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# 넘파이로 텐서 조작하기.\n",
    "# 배열에 있는 특정 원소들을 선택하는 것을 슬라이싱(slicing) 이라고 합니다. \n",
    "# 예로 11 번쨰에서 101번쨰까지 숫자를 선택 후 (90, 28, 28) 크기의 배열을 만듭니다.\n",
    "\n",
    "my_slice = train_images[10:100]\n",
    "print(my_slice.shape)\n",
    "\n",
    "# 각 배열의 축을 따라 어떤 인덱스 사이도 선택 가능. 14 x 14 픽셀 선택해보자.\n",
    "my_slice = train_images[:, 14:, 14:]\n",
    "\n",
    "# 음수 인덱스도 사용 가능. 14 x 14 픽셀 조각을 이미지에서 잘라 내려보면?\n",
    "my_slice = train_images[:, 7:-7, 7:-7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서의 실제 사례.\n",
    "\n",
    "벡터 데이터 : (sample, features) 크기의 2D 텐서\n",
    "\n",
    "시계열 데이터 또는 시퀸스 데이터 : (samples, timesteps, features) 크기의 3D 텐서.\n",
    "\n",
    "이미지 : (samples, height, width, channels) 또는 (samples, channels, height, width) 크기의 4D 텐서.\n",
    "\n",
    "동영상 : (samples, frames, width, channels) 또는 (samples, frames, channels, height, width) zmrldml 5D 텐서 .\n",
    "\n",
    "벡터 데이터.\n",
    "\n",
    "여기서 첫 번쨰 축은 샘플 축이고, 두 번쨰 축은 특성 축(feature axis) 입니다.\n",
    "\n",
    "사람의 나이, 우편 번호, 소득으로 구성된 인구 통계 데이터는 각 사람은 3개의 값을 가진 벡터로 구성되고 10만 명이 포함된 전체 데이터셋은 \n",
    "(100000, 3) 크기의 텐서로 저장될 수 있습니다.\n",
    "\n",
    "(공통 단어 2만 개로 만든 사전) 각 단어가 등장한 횟수로 표현된 텍스트 문서 데이터 셋, 각 문서는 2만 개의 원소(사전에 있는 단어마다 하나의 원소에 대응합니다)를 가진 벡터로 인코딩될 수 있습니다.\n",
    "\n",
    "500개의 문서로 이루어진 전체 데이터셋은 (500, 20000) 크기의 텐서로 저장됩니다. \n",
    "\n",
    "\n",
    "\n",
    "시계열 데이터 또는 시퀸스 데이터 \n",
    "\n",
    "데이터에서 시간이 (도는 연속된 숫자가) 중요할 떄는 시간 축을 포함, 3D 텐서로 저장됩니다.\n",
    "각 샘플은 벡터(2D 텐서)의 시퀸스로 인코딩되므로 배치 데이터는 3D 텐서로 인코딩될 것 입니다.\n",
    "\n",
    "이미지 데이터 \n",
    "\n",
    "높이, 너비, 커럴 채널의 3차원으로 이루어집니다. \n",
    "(MNIST 숫자처럼) 흑백 이미지는 하나의 컬러 채널만을 가지고 있어 2D 텐서로 저장될 수 있지만 관례상 이미지 텐서는 항상 3D로 저장됩니다.\n",
    "흑백 이미지의 경우 컬러 채널의 차원 크기는 1 입니다. 256 x 256 크기의 흑백 이미지에 대한 128개의 배치는 (128, 256, 256, 1) 크기의 텐서로 저장될 수 있습니다.\n",
    "\n",
    "컬러 이미지에 대한 128 개의 배치라면 (128, 256, 256, 3) 크기의 텐서로 저장될 수 있습니다.\n",
    "\n",
    "tensorflow 형식에서는 (samples, height, width, color_depth) 컬러 채널의 깊이를 끝에 놓습니다. \n",
    "\n",
    "\n",
    "비디오 데이터 \n",
    "\n",
    "생략 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망의 톱니바퀴 : 텐서 연산\n",
    "\n",
    "컴퓨터 이진수 AND OR 처럼 신경망에서도 데이터 텐서에 적용하는 몇 종류의 텐서 연산으로 나타낼 수 있습니다.\n",
    "예를 들어 텐서 덧셈이나 텐서 곱셈 등 입니다.\n",
    "\n",
    "첫 번쨰 예제에서는 Dense 층을 쌓아서 신경망을 만들었습니다. \n",
    "\n",
    "keras.layers.Dense(512, activation='relu') \n",
    "\n",
    "이 층은 2D 텐서를 입력으로 받고 입력 텐서의 새로운 표현인 또 다른 2D 텐서를 반환하는 함수처럼 해석 할 수 있습니다.\n",
    "W는 2D 텐서고, b는 벡터 입니다. 둘 모두 층의 속성입니다.\n",
    "\n",
    "output = relu(dot(W, input) + b) \n",
    "\n",
    "여기에선 3 개의 텐서 연산이 있음.  입력 텐서와 텐서 W 사이의 점곱(dot), 점곱의 결과인 2D 텐서와 벡터 b 사이의 덧셈(+),\n",
    "마지막으로 relu(렐루) 연산입니다 relu(x)는 max(x, 0)입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원소별 연산 \n",
    "\n",
    "relu 함수와 덧셈은 원소별 연산 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2 # x는 2D 넘파이 배열입니다.\n",
    "    \n",
    "    x = x.copy() # 입력 텐서 자체를 바꾸지 않도록 복사합니다.\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] = max(x[i, j], 0)\n",
    "            return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "덧셈도 동일합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add(x, y):\n",
    "    assert len(x.shape) == 2 # x와 y는 2D 넘파이 배열입니다.\n",
    "    assert x.shape == y.shape \n",
    "    \n",
    "    x = x.copy() # 입력 텐서 자체를 바꾸지 않도록 복사합니다.\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[i, j]\n",
    "            return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "같은 원리로 원소별 곱셈, 뺼셈 등을 할 수 있습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "브로드캐스팅\n",
    "\n",
    "작은 텐서가 큰 텐서의 크기에 맞추어 브로드캐스팅 됩니다.  \n",
    "\n",
    "1. 큰 텐서의 ndim에 맞도록 작은 텐서에 축이 추가 됩니다.\n",
    "2. 작은 텐서가 새 축을 따라 큰 텐서의 크기에 맞도록 반복됩니다. \n",
    "\n",
    "예를 들어 x의 크기는 (32, 10) 이고, y의 크기는 (10,) 가정. \n",
    "먼저 y에 비어 있는 첫 번쨰 축은 추가하여 크기를 (1, 10) 으로 만듭니다.\n",
    "\n",
    "그리고 y를 이 축에 32번 반복하여 텐서 Y의 크기는 (32, 10)이 됩니다. \n",
    "여기에서 Y[i, :] == y for i in range(0, 32) 입니다. \n",
    "이제 X와 Y의 크기가 같으므로 더할 수 있습니다. \n",
    "\n",
    "구현 입장에서는 새로운 텐서가 만들어지면 매우 비효율적이므로 어떤 2D 텐서도 만들어지지 않습니다. \n",
    "\n",
    "그냥 기억만 해놓자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x, y):\n",
    "    assert len(x.shape) == 2 # x 2D 넘파이 배열.\n",
    "    assert len(y.shape) == 1 # Y 넘파이 벡터. \n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    \n",
    "    x = x.copy() # 입력 텐서 자체를 바꾸지 않도록 복사합니다.\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[j]\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서 점곱 \n",
    "\n",
    "텐서 곱셈이라고 불리는 점곱 연산은 가장 널리 사용되고 유용한 텐서 연산입니다.\n",
    "\n",
    "넘파이,케라스, 씨아노, 텐서플로에서 원소별 곱셈은 * 연산자를 사용합니다. \n",
    "\n",
    "텐서플로에서는 dot 연산자가 다르지만 넘파이와 케라스는 점곱 연산에 dot 연산자를 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "벡터 x와 y의 점곱은 다음과 같이 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_vector_dot(x, y):\n",
    "    assert len(x.shape) == 1\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    \n",
    "    z = 0.\n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "행렬 x와 벡터 y사이에서도 점곱이 가능합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def naive_matrix_vector_dot(x, y):\n",
    "    assert len(x.shape) == 2 # x 는 넘파이 행렬.\n",
    "    assert len(y.shape) == 1 # y 는 넘파이 벡터.\n",
    "    assert x.shape[1] == y.shape[0] # x의 두 번쨰 차원과 y의 첫 번쨰 차원이 같아야 합니다. \n",
    "    \n",
    "    z = np.zeros(x.shape[0]) # 이 연산은 x의 행과 같은 크기의 0이 채워진 벡터를 만듭니다.\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            z[i] += x[i, j] * y[j]\n",
    "            return z "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자주 쓰이는 텐서 크기 변환의 전치(transposition)입니다.  전치는 행과 열을 바꾸는 것을 의미합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 300)\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((300, 20))\n",
    "x = np.transpose(x) \n",
    "print(x.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "요약 \n",
    "\n",
    "학습은 훈련 데이터 샘플과 그에 상응하는 타깃이 주어졌을 떄 손실 함수를 최소화하는 모델 파라미터의 조합을 찾는 것을 의미합니다.\n",
    "\n",
    "데아터 샘플과 타깃의 배치를 랜덤하게 뽑고 이 배치에서 손실에 대한 파라미터의 그래디언트를 계산함으로써 학습이 진행됩니다.\n",
    "네트워크의 파라미터는 그래디언트의 반대 방향으로 조금씩(학습률의 의해 정의된 크기만큼) 움직입니다. \n",
    "\n",
    "전체 학습 과정은 신경망이 미분 가능한 텐서 연산으로 연결되어 있기 떄문에 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
